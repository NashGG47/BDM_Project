import duckdb
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json

# Create output directory for exploitation results
EXPLOITATION_DIR = Path("storage/delta/exploitation/")
EXPLOITATION_DIR.mkdir(parents=True, exist_ok=True)

# Connect to DuckDB
con = duckdb.connect("bdm_project.duckdb")

print("=" * 60)
print("EXPLOITATION ZONE - Urban Mobility Analytics")
print("=" * 60)

# ============================================
# 1. PASSENGER VOLUME ANALYTICS
# ============================================
print("\n1. PASSENGER VOLUME ANALYTICS")
print("-" * 40)

# 1.1 Peak Hour Detection
print("\n1.1 Detecting Peak Hours...")
peak_hours_query = """
WITH hourly_totals AS (
    SELECT 
        tramo_horario,
        SUM(viajeros_subidos) as total_boardings,
        SUM(viajeros_bajados) as total_alightings,
        SUM(viajeros_subidos + viajeros_bajados) as total_passengers
    FROM trusted_passenger_volume
    GROUP BY tramo_horario
    ORDER BY total_passengers DESC
)
SELECT * FROM hourly_totals LIMIT 10
"""
peak_hours_df = con.execute(peak_hours_query).df()
print("\nTop 10 Peak Hours (System-wide):")
print(peak_hours_df)

# Save peak hours analysis
peak_hours_df.to_parquet(EXPLOITATION_DIR / "peak_hours_analysis.parquet")

# 1.2 Busiest Stations Analysis
print("\n1.2 Analyzing Busiest Stations...")
busiest_stations_query = """
SELECT 
    codigo_estacion,
    nombre_estacion,
    SUM(viajeros_subidos) as total_boardings,
    SUM(viajeros_bajados) as total_alightings,
    SUM(viajeros_subidos + viajeros_bajados) as total_passenger_flow,
    AVG(viajeros_subidos) as avg_boardings_per_slot,
    AVG(viajeros_bajados) as avg_alightings_per_slot
FROM trusted_passenger_volume
GROUP BY codigo_estacion, nombre_estacion
ORDER BY total_passenger_flow DESC
"""
busiest_stations_df = con.execute(busiest_stations_query).df()
print("\nBusiest Stations by Total Passenger Flow:")
print(busiest_stations_df.head())

# Save station analysis
busiest_stations_df.to_parquet(EXPLOITATION_DIR / "station_usage_metrics.parquet")

# 1.3 Peak Hours by Station
print("\n1.3 Finding Peak Hours for Each Station...")
station_peaks_query = """
WITH station_hourly AS (
    SELECT 
        codigo_estacion,
        nombre_estacion,
        tramo_horario,
        SUM(viajeros_subidos + viajeros_bajados) as passenger_flow,
        ROW_NUMBER() OVER (PARTITION BY codigo_estacion ORDER BY SUM(viajeros_subidos + viajeros_bajados) DESC) as rn
    FROM trusted_passenger_volume
    GROUP BY codigo_estacion, nombre_estacion, tramo_horario
)
SELECT 
    codigo_estacion,
    nombre_estacion,
    tramo_horario as peak_hour,
    passenger_flow as peak_flow
FROM station_hourly
WHERE rn = 1
ORDER BY passenger_flow DESC
"""
station_peaks_df = con.execute(station_peaks_query).df()
print("\nPeak Hour for Each Station:")
print(station_peaks_df)

# ============================================
# 2. ENVIRONMENTAL INDICATORS KPIs
# ============================================
print("\n\n2. ENVIRONMENTAL INDICATORS KPIs")
print("-" * 40)

# 2.1 CO2 Emission Trends (using actual column names)
print("\n2.1 Calculating CO₂ Emission Trends...")
co2_trends_query = """
SELECT 
    year,
    iesidad_carboo_g_co2_u as co2_intensity,
    gwh_oal as total_energy_gwh,
    -- Calculate estimated total CO2 based on energy and intensity
    (iesidad_carboo_g_co2_u * gwh_oal * 1000000) as estimated_total_co2_kg
FROM trusted_environmental_indicators
ORDER BY year
"""
co2_trends_df = con.execute(co2_trends_query).df()
print("\nCO₂ Emission Trends by Year:")
print(co2_trends_df)

# Calculate year-over-year changes
co2_trends_df['co2_intensity_change_pct'] = co2_trends_df['co2_intensity'].pct_change() * 100
co2_trends_df['energy_change_pct'] = co2_trends_df['total_energy_gwh'].pct_change() * 100

# Save CO2 trends
co2_trends_df.to_parquet(EXPLOITATION_DIR / "co2_emission_trends.parquet")

# 2.2 Energy Efficiency KPIs (using actual column names)
print("\n2.2 Energy Efficiency Analysis...")
energy_kpi_query = """
SELECT 
    year,
    gwh_raccio_elecrica as gwh_traccion_electrica,
    gwh_l_diesel,
    gwh_oal as gwh_total,
    iesidad_eergeica_wh_u as intensidad_energetica_wh_ut,
    -- Calculate electric vs diesel ratio
    ROUND((gwh_raccio_elecrica / gwh_oal) * 100, 2) as electric_percentage,
    ROUND((gwh_l_diesel / gwh_oal) * 100, 2) as diesel_percentage
FROM trusted_environmental_indicators
ORDER BY year
"""
energy_kpi_df = con.execute(energy_kpi_query).df()
print("\nEnergy Source Distribution:")
print(energy_kpi_df)

# Save energy KPIs
energy_kpi_df.to_parquet(EXPLOITATION_DIR / "energy_efficiency_kpis.parquet")

# 2.3 Environmental Investment ROI (using actual column names)
print("\n2.3 Environmental Investment Analysis...")
investment_roi_query = """
WITH yearly_metrics AS (
    SELECT 
        year,
        gasos_iversioes_ambieales_euros as environmental_investment,
        iesidad_carboo_g_co2_u as co2_intensity,
        LAG(iesidad_carboo_g_co2_u) OVER (ORDER BY year) as prev_co2_intensity
    FROM trusted_environmental_indicators
)
SELECT 
    year,
    environmental_investment,
    co2_intensity,
    ROUND((prev_co2_intensity - co2_intensity), 2) as co2_reduction,
    CASE 
        WHEN environmental_investment > 0 AND (prev_co2_intensity - co2_intensity) > 0
        THEN ROUND((prev_co2_intensity - co2_intensity) / environmental_investment * 1000000, 4)
        ELSE NULL 
    END as co2_reduction_per_million_invested
FROM yearly_metrics
WHERE year > (SELECT MIN(year) FROM trusted_environmental_indicators)
ORDER BY year
"""
investment_roi_df = con.execute(investment_roi_query).df()
print("\nEnvironmental Investment ROI:")
print(investment_roi_df)

# ============================================
# 3. SPATIAL INTEGRATION WITH DISTRICTS
# ============================================
print("\n\n3. SPATIAL INTEGRATION ANALYSIS")
print("-" * 40)

# 3.1 Create aggregated KPIs by district (simulated)
print("\n3.1 Creating District-Level KPIs...")

# Get district information
districts_query = """
SELECT 
    CODI_UA as district_code,
    NOM as district_name,
    AREA as district_area_m2,
    PERIMETRE as district_perimeter_m
FROM trusted_admin_boundaries
ORDER BY district_code
"""
districts_df = con.execute(districts_query).df()

# Create simulated station-to-district mapping based on station names
# In a real scenario, this would be done with spatial joins
station_district_mapping = {
    'PLAÇA  DE CATALUNYA': '01',  # Ciutat Vella
    'ARC DE TRIOMF': '01',  # Ciutat Vella
    'BARCELONA-CLOT-ARAGO': '10',  # Sant Martí
    'LA SAGRERA-MERIDIANA': '09',  # Sant Andreu
    'SANT ANDREU ARENAL': '09',  # Sant Andreu
    'BARCELONA-SANT ANDREU COMTAL': '09',  # Sant Andreu
    'MONTCADA-BIFURCACIO': '08',  # Nou Barris (nearby)
    'TORRE DEL BARO': '08',  # Nou Barris
}

# Apply mapping to station data
station_with_districts_query = """
SELECT 
    pv.*,
    CASE 
        WHEN nombre_estacion = 'PLAÇA  DE CATALUNYA' THEN '01'
        WHEN nombre_estacion = 'ARC DE TRIOMF' THEN '01'
        WHEN nombre_estacion = 'BARCELONA-CLOT-ARAGO' THEN '10'
        WHEN nombre_estacion = 'LA SAGRERA-MERIDIANA' THEN '09'
        WHEN nombre_estacion = 'SANT ANDREU ARENAL' THEN '09'
        WHEN nombre_estacion = 'BARCELONA-SANT ANDREU COMTAL' THEN '09'
        WHEN nombre_estacion = 'MONTCADA-BIFURCACIO' THEN '08'
        WHEN nombre_estacion = 'TORRE DEL BARO' THEN '08'
        ELSE 'XX'  -- Outside Barcelona
    END as district_code
FROM trusted_passenger_volume pv
"""

# Calculate passenger flow by district
district_passenger_flow_query = f"""
WITH station_districts AS (
    {station_with_districts_query}
)
SELECT 
    sd.district_code,
    COUNT(DISTINCT sd.codigo_estacion) as num_stations,
    SUM(sd.viajeros_subidos) as total_boardings,
    SUM(sd.viajeros_bajados) as total_alightings,
    SUM(sd.viajeros_subidos + sd.viajeros_bajados) as total_passenger_flow
FROM station_districts sd
WHERE sd.district_code != 'XX'
GROUP BY sd.district_code
ORDER BY total_passenger_flow DESC
"""
district_flow_df = con.execute(district_passenger_flow_query).df()

# Merge with district names
district_flow_df = district_flow_df.merge(
    districts_df[['district_code', 'district_name']], 
    on='district_code', 
    how='left'
)

print("\nPassenger Flow by District:")
print(district_flow_df)

# Save district analysis
district_flow_df.to_parquet(EXPLOITATION_DIR / "district_passenger_flow.parquet")

# ============================================
# 4. INTEGRATED KPI DASHBOARD DATA
# ============================================
print("\n\n4. CREATING INTEGRATED KPI SUMMARY")
print("-" * 40)

# Create a summary dashboard dataset
kpi_summary = {
    "generation_timestamp": datetime.now().isoformat(),
    "passenger_metrics": {
        "total_stations": int(busiest_stations_df['codigo_estacion'].nunique()),
        "total_daily_passengers": int(busiest_stations_df['total_passenger_flow'].sum()),
        "busiest_station": busiest_stations_df.iloc[0]['nombre_estacion'],
        "busiest_station_flow": int(busiest_stations_df.iloc[0]['total_passenger_flow']),
        "system_peak_hour": peak_hours_df.iloc[0]['tramo_horario'],
        "peak_hour_passengers": int(peak_hours_df.iloc[0]['total_passengers'])
    },
    "environmental_metrics": {
        "latest_year": int(co2_trends_df['year'].max()),
        "latest_co2_intensity": float(co2_trends_df[co2_trends_df['year'] == co2_trends_df['year'].max()]['co2_intensity'].iloc[0]),
        "co2_reduction_2013_2019": float(
            co2_trends_df[co2_trends_df['year'] == 2013]['co2_intensity'].iloc[0] - 
            co2_trends_df[co2_trends_df['year'] == 2019]['co2_intensity'].iloc[0]
        ),
        "electric_percentage_2019": float(energy_kpi_df[energy_kpi_df['year'] == 2019]['electric_percentage'].iloc[0]),
        "total_environmental_investment": int(investment_roi_df['environmental_investment'].sum())
    },
    "spatial_metrics": {
        "districts_with_stations": int(district_flow_df['district_code'].nunique()),
        "busiest_district": district_flow_df.iloc[0]['district_name'] if len(district_flow_df) > 0 else "N/A",
        "busiest_district_flow": int(district_flow_df.iloc[0]['total_passenger_flow']) if len(district_flow_df) > 0 else 0
    }
}

# Save KPI summary
with open(EXPLOITATION_DIR / "kpi_summary.json", "w") as f:
    json.dump(kpi_summary, f, indent=2)

print("\nKPI Summary Generated:")
print(json.dumps(kpi_summary, indent=2))

# Close connection
con.close()

print("\n" + "=" * 60)
print("EXPLOITATION ZONE PROCESSING COMPLETE!")
print(f"Results saved to: {EXPLOITATION_DIR}")
print("=" * 60)